{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import fractional_matrix_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  try to reproduce the idea of [this paper](http://faculty.olin.edu/dshuman/Papers/Conference/Thanou_et_al_GlobalSIP_2013.pdf).\n",
    "In particular we are going to define a dictionary composed of $S$ subdictionaries, each of them parametrized as a polynomial of the laplacian: \n",
    "\n",
    "$$\n",
    "D_s = \\sum_{k = 0}^K \\alpha_{sk} \\mathcal{L}^k, \\ s = 1,...,S\n",
    "$$\n",
    "\n",
    "this dictionary has the structure of a convolutional filter bank, and by looking at the spectrum of each subdictionary we find out that each atom of each subdictionary has a localization quality over a node $v \\in V$.\n",
    "\n",
    "Assuming a graph $G(V,E)$, and a set of $N$ observed signals $Y \\in \\mathbb{R}^{V \\times N}$, we have the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\underset{X,D}{\\mathrm{min}} & ||Y -DX||_F^2 + \\lambda ||X||_{:,1}\\\\\n",
    "& D_s = \\sum_{k = 0}^K \\alpha_{sk} \\mathcal{L}^k, & s = 1,...,S \\\\\n",
    "& 0 \\preceq D_s \\preceq k\\mathbb{I}, & s = 1,...,S \\\\\n",
    "& (c - \\epsilon) \\mathbb{I} \\preceq \\sum_{s=1}^S D_s \\preceq (c + \\epsilon)\\mathbb{I}\n",
    "\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where the constraints are meant to grant that the spectrum of each filter and of the over all dictionary meaningfully covers the representations of the signals. \n",
    "\n",
    "The problem can be solved alternating the optimization of $D$, i.e. of its parametrization, and of the sparse coding $X$ of each 0-cochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80\n",
    "cutoff = 0.5\n",
    "theta = 0.9\n",
    "\n",
    "points = np.random.rand(N, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianKernel(P1, P2, theta):\n",
    "\n",
    "    return np.exp(- np.linalg.norm(P1 - P2)**2/(2*theta**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((N,N))\n",
    "W = np.zeros((N,N))\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        \n",
    "        A[i,j] = np.linalg.norm(points[i,:] - points[j,:]) <= cutoff\n",
    "        A[j,i] = np.linalg.norm(points[i,:] - points[j,:]) <= cutoff\n",
    "\n",
    "        W[i,j] = GaussianKernel(points[i,:], points[j,:], theta)\n",
    "        W[j,i] = GaussianKernel(points[i,:], points[j,:], theta)\n",
    "\n",
    "W = W * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.diag(np.sum(A, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = D - W \n",
    "L = fractional_matrix_power(D, -0.5) @ L @ fractional_matrix_power(D, -0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a band-localized overcomplete dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "band1 = np.array(list(range(0,20)))\n",
    "band2 = np.concatenate([np.array(list(range(20,30))), np.array(list(range(70,80)))])\n",
    "band3 = np.array(list(range(30,50)))\n",
    "band4 = np.array(list(range(50,70)))\n",
    "\n",
    "bands = [band1, band2, band3, band4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda, U = np.linalg.eig(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 320\n",
    "DD = np.zeros((N, J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(J): \n",
    "\n",
    "    B = np.random.choice(4)\n",
    "\n",
    "    h = np.copy(Lambda)\n",
    "    h[~bands[B]] = 0\n",
    "    h *= np.random.rand(h.shape[0],1)[:,0]\n",
    "\n",
    "    n = np.random.choice(N)\n",
    "\n",
    "    DD[:,j] = (U @ np.diag(h) @ U.T)[:,n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1000 \n",
    "Y_train = np.zeros((N,M))\n",
    "\n",
    "for m in range(M):\n",
    "    T = np.random.choice(J, 4)\n",
    "    Y_train[:,m] = DD[:,T] @ np.random.rand(4)\n",
    "\n",
    "test_size = 2000\n",
    "Y_test = np.zeros((N,test_size))\n",
    "\n",
    "for t in range(test_size):\n",
    "    T = np.random.choice(J, 4)\n",
    "    Y_test[:,t] = DD[:,T] @ np.random.rand(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary learning algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "eps = 0.01\n",
    "\n",
    "T0 = 4\n",
    "S = 4\n",
    "K = 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
